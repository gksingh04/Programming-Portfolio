which(redundant)
rules.pruned <- rules[!redundant]
rules.pruned <- sort(rules.pruned, by="lift")
inspect(rules.pruned)
frequentItems <- eclat(basket, parameter = list(supp = 0.5, maxlen = 15))
inspect(frequentItems)
# Targeting Items
rules<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="milk"),
control = list(verbose=F))
# Targeting Items
rules<-apriori(data=basket, parameter=list(supp=0.001,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:3])
# Targeting Items
rules<-apriori(data=basket, parameter=list(supp=0.5,conf = 0.75,minlen=2),
appearance = list(default="rhs",lhs="milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:4])
# Targeting Items
rules<-apriori(data=basket, parameter=list(supp=0.5,conf = 0.75,minlen=2),
appearance = list(default="rhs",lhs="milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:3])
# Targeting Items
rules<-apriori(data=basket, parameter=list(supp=0.5,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:3])
# Targeting Items
rules<-apriori(data=basket, parameter=list(supp=0.001,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:3])
# Targeting Items
rules<-apriori(data=basket, parameter=list(supp=0.001,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="bread"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:3])
# Targeting Items
rules<-apriori(data=basket, parameter=list(supp=0.001,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="bread"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:4])
# Visualization
plot(rules)
plot(rules,method="graph",control=list(verbose=F))
# Visualization
plot(rules, jitter = 0)
plot(rules,method="graph",control=list(verbose=F))
plot(rules[1:6], method = "paracoord", control = list(reorder = TRUE))
plot(rules[1:4], method = "paracoord", control = list(reorder = TRUE))
arulesViz::plotly_arules(rules, method="matrix", measure=c("support","confidence"))
# Reading the data file
mydata<-read.csv("C:\\Users\\hp\\Documents\\transaction data.csv",header=T)
head(mydata)
mydata$Transaction.Id <- as.factor(mydata$Transaction.Id)
summary(mydata)
data <- list(
c("bread","cheese","egg","juice"),
c("bread","cheese","juice"),
c("bread","milk","yogurt"),
c("bread","juice","milk"),
c("cheese","juice","milk")
)
#apriori algorithm
library(arules)
rules <- apriori(mydata)
summary(rules)
data <- as(data, "transactions")
inspect(data)
basket <- as(data, "tidLists")
inspect(basket)
# Rules with specified parameter valus
rules <- apriori(mydata,parameter = list(minlen=2, maxlen=10,supp=.5, conf=.75))
inspect(rules)
# Reading the data file
mydata<-read.csv("C:\\Users\\hp\\Documents\\transaction data.csv",header=T)
head(mydata)
mydata$Transaction.Id <- as.factor(mydata$Transaction.Id)
summary(mydata)
data <- list(
c("bread","cheese","egg","juice"),
c("bread","cheese","juice"),
c("bread","milk","yogurt"),
c("bread","juice","milk"),
c("cheese","juice","milk")
)
#apriori algorithm
library(arules)
rules <- apriori(mydata)
summary(rules)
data <- as(data, "transactions")
inspect(data)
basket <- as(data, "tidLists")
inspect(basket)
# Rules with specified parameter valus
rules <- apriori(basket,parameter = list(minlen=2, maxlen=10,supp=.5, conf=.75))
inspect(rules)
# Sorting stuff out
rules<-sort(rules, by="confidence", decreasing=TRUE)
rules <- apriori(basket, parameter = list(supp = 0.5, conf = 0.75,maxlen=3))
rules_conf <- sort (rules, by="confidence", decreasing=TRUE) # 'high-confidence' rules.
inspect(head(rules_conf))
# Redundancies
redundant <- is.redundant(rules, measure="confidence")
which(redundant)
rules.pruned <- rules[!redundant]
rules.pruned <- sort(rules.pruned, by="lift")
inspect(rules.pruned)
frequentItems <- eclat(basket, parameter = list(supp = 0.5, maxlen = 15))
inspect(frequentItems)
# Targeting Items
rules<-apriori(data=basket, parameter=list(supp=0.001,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="bread"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:4])
# Visualization
plot(rules, jitter = 0)
plot(rules,method="graph",control=list(verbose=F))
plot(rules[1:4], method = "paracoord", control = list(reorder = TRUE))
# Reading the data file
mydata<-read.csv("C:\\Users\\hp\\Documents\\transaction data.csv",header=T)
head(mydata)
mydata$Transaction.Id <- as.factor(mydata$Transaction.Id)
summary(mydata)
data <- list(
c("bread","cheese","egg","juice"),
c("bread","cheese","juice"),
c("bread","milk","yogurt"),
c("bread","juice","milk"),
c("cheese","juice","milk")
)
#apriori algorithm
library(arules)
rules <- apriori(mydata)
summary(rules)
data <- as(data, "transactions")
inspect(data)
basket <- as(data, "tidLists")
inspect(basket)
# Rules with specified parameter valus
rules <- apriori(basket,parameter = list(minlen=2, maxlen=10,supp=.5, conf=.75))
inspect(rules)
# Sorting stuff out
rules<-sort(rules, by="confidence", decreasing=TRUE)
rules <- apriori(basket, parameter = list(supp = 0.5, conf = 0.75,maxlen=3))
rules_conf <- sort (rules, by="confidence", decreasing=TRUE) # 'high-confidence' rules.
inspect(head(rules_conf))
frequentItems <- eclat(basket, parameter = list(supp = 0.5, maxlen = 15))
inspect(frequentItems)
# Redundancies
redundant <- is.redundant(rules, measure="confidence")
which(redundant)
rules.pruned <- rules[!redundant]
rules.pruned <- sort(rules.pruned, by="lift")
inspect(rules.pruned)
# Targeting Items
rules<-apriori(data=basket, parameter=list(supp=0.001,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="bread"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:4])
# Visualization
plot(rules, jitter = 0)
plot(rules,method="graph",control=list(verbose=F))
plot(rules[1:4], method = "paracoord", control = list(reorder = TRUE))
arulesViz::plotly_arules(rules, method="matrix", measure=c("support","confidence"))
# Targeting Items
rules<-apriori(data=basket, parameter=list(supp=0.02,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="bread"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:4])
# Targeting Items
rules<-apriori(data=basket, parameter=list(supp=0.02,conf = 0.5,minlen=2),
appearance = list(default="rhs",lhs="bread"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:4])
# Targeting Items
rules<-apriori(data=basket, parameter=list(supp=0.5,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="bread"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:4])
# Targeting Items
rules<-apriori(data=basket, parameter=list(supp=0.001,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="bread"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:4])
# Reading the data file
mydata<-read.csv("C:\\Users\\hp\\Documents\\transaction data.csv",header=T)
head(mydata)
mydata$Transaction.Id <- as.factor(mydata$Transaction.Id)
summary(mydata)
data <- list(
c("bread","cheese","egg","juice"),
c("bread","cheese","juice"),
c("bread","milk","yogurt"),
c("bread","juice","milk"),
c("cheese","juice","milk")
)
#apriori algorithm
library(arules)
rules <- apriori(mydata)
summary(rules)
data <- as(data, "transactions")
inspect(data)
basket <- as(data, "tidLists")
inspect(basket)
# Rules with specified parameter valus
rules <- apriori(basket,parameter = list(minlen=2, maxlen=10,supp=.5, conf=.75))
inspect(rules)
# Sorting stuff out
rules<-sort(rules, by="confidence", decreasing=TRUE)
rules <- apriori(basket, parameter = list(supp = 0.5, conf = 0.75,maxlen=3))
rules_conf <- sort (rules, by="confidence", decreasing=TRUE) # 'high-confidence' rules.
inspect(head(rules_conf))
# Redundancies
redundant <- is.redundant(rules, measure="confidence")
which(redundant)
rules.pruned <- rules[!redundant]
rules.pruned <- sort(rules.pruned, by="lift")
inspect(rules.pruned)
# Targeting Items
rules<-apriori(data=basket, parameter=list(supp=0.001,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="bread"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:4])
# Visualization
plot(rules, jitter = 0)
plot(rules,method="graph",control=list(verbose=F))
plot(rules[1:4], method = "paracoord", control = list(reorder = TRUE))
# Reading the data file
mydata<-read.csv("C:\\Users\\hp\\Documents\\transaction data.csv",header=T)
head(mydata)
mydata$Transaction.Id <- as.factor(mydata$Transaction.Id)
summary(mydata)
data <- list(
c("bread","cheese","egg","juice"),
c("bread","cheese","juice"),
c("bread","milk","yogurt"),
c("bread","juice","milk"),
c("cheese","juice","milk")
)
#apriori algorithm
library(arules)
rules <- apriori(mydata)
summary(rules)
data <- as(data, "transactions")
inspect(data)
basket <- as(data, "tidLists")
inspect(basket)
# Rules with specified parameter valus
rules <- apriori(basket,parameter = list(minlen=2, maxlen=10,supp=.5, conf=.75))
inspect(rules)
# Sorting stuff out
rules<-sort(rules, by="confidence", decreasing=TRUE)
rules <- apriori(basket, parameter = list(supp = 0.5, conf = 0.75,maxlen=3))
rules_conf <- sort (rules, by="confidence", decreasing=TRUE)
inspect(head(rules_conf))
# Redundancies
redundant <- is.redundant(rules, measure="confidence")
which(redundant)
rules.pruned <- rules[!redundant]
rules.pruned <- sort(rules.pruned, by="lift")
inspect(rules.pruned)
# Targeting Items
rules<-apriori(data=basket, parameter=list(supp=0.001,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="bread"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:4])
# Visualization
plot(rules, jitter = 0)
plot(rules,method="graph",control=list(verbose=F))
plot(rules[1:4], method = "paracoord", control = list(reorder = TRUE))
arulesViz::plotly_arules(rules, method="matrix", measure=c("support","confidence"))
library(arulesViz)
# Reading the data file
mydata<-read.csv("C:\\Users\\hp\\Documents\\transaction data.csv",header=T)
head(mydata)
mydata$Transaction.Id <- as.factor(mydata$Transaction.Id)
summary(mydata)
data <- list(
c("bread","cheese","egg","juice"),
c("bread","cheese","juice"),
c("bread","milk","yogurt"),
c("bread","juice","milk"),
c("cheese","juice","milk")
)
#apriori algorithm
library(arules)
rules <- apriori(mydata)
summary(rules)
data <- as(data, "transactions")
inspect(data)
basket <- as(data, "tidLists")
inspect(basket)
# Rules with specified parameter valus
rules <- apriori(basket,parameter = list(minlen=2, maxlen=10,supp=.5, conf=.75))
inspect(rules)
# Sorting stuff out
rules<-sort(rules, by="confidence", decreasing=TRUE)
rules <- apriori(basket, parameter = list(supp = 0.5, conf = 0.75,maxlen=3))
rules_conf <- sort (rules, by="confidence", decreasing=TRUE)
inspect(head(rules_conf))
# Redundancies
redundant <- is.redundant(rules, measure="confidence")
which(redundant)
rules.pruned <- rules[!redundant]
rules.pruned <- sort(rules.pruned, by="lift")
inspect(rules.pruned)
# Targeting Items
rules<-apriori(data=basket, parameter=list(supp=0.001,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="bread"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:4])
# Visualization
plot(rules, jitter = 0)
plot(rules,method="graph",control=list(verbose=F))
plot(rules[1:4], method = "paracoord", control = list(reorder = TRUE))
# Visualization
plot(rules)
arulesViz::plotly_arules(rules, method="matrix", measure=c("support","confidence"))
library(arules)
library(arulesViz)
library(datasets)
# Load the data set
data(Groceries)
str(Groceries)
head(Groceries)
View(Groceries)
View(Groceries@itemsetInfo)
View(Groceries@itemInfo)
# Libraries
library(caret)
library(pROC)
library(mlbench)
qplot (Petal.Length, Petal.Width, data=iris, color=Species)
#load data
df <- data(iris)
# see the studcture
head(iris)
#Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(iris), 0.9 * nrow(iris))
#the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
#Run nomalization on first 4 coulumns of dataset because they are the predictors
iris_norm <- as.data.frame(lapply(iris[,c(1,2,3,4)], nor))
summary(iris_norm)
#extract training set
iris_train <- iris_norm[ran,]
#extract testing set
iris_test <- iris_norm[-ran,]
#extract 5th column of train dataset because it will be used as 'cl' argument in knn function.
iris_target_category <- iris[ran,5]
#extract 5th column if test dataset to measure the accuracy
iris_test_category <- iris[-ran,5]
#load the package class
library(class)
#run knn function
pr <- knn(iris_train,iris_test,cl=iris_target_category,k=5)
print(pr,digits = 3)
#create confusion matrix
tab <- table(pr,iris_test_category)
print(tab,digits = 3)
#this function divides the correct predictions by total number of predictions that tell us how accurate teh model is.
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
#Cross Table
library(gmodels)
CrossTable(x = iris_test_category, y = pr, prop.chisq=FALSE)
# Libraries
library(caret)
library(pROC)
library(mlbench)
qplot (Petal.Length, Petal.Width, data=iris, color=Species)
#load data
df <- data(iris)
# see the studcture
head(iris)
#Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(iris), 0.9 * nrow(iris))
#the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
#Run nomalization on first 4 coulumns of dataset because they are the predictors
iris_norm <- as.data.frame(lapply(iris[,c(1,2,3,4)], nor))
summary(iris_norm)
#extract training set
iris_train <- iris_norm[ran,]
#extract testing set
iris_test <- iris_norm[-ran,]
#extract 5th column of train dataset because it will be used as 'cl' argument in knn function.
iris_target_category <- iris[ran,5]
#extract 5th column if test dataset to measure the accuracy
iris_test_category <- iris[-ran,5]
#load the package class
library(class)
#run knn function
pr <- knn(iris_train,iris_test,cl=iris_target_category,k=5)
print(pr,digits = 3)
#create confusion matrix
tab <- table(pr,iris_test_category)
print(tab,digits = 3)
#this function divides the correct predictions by total number of predictions that tell us how accurate teh model is.
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
#Cross Table
library(gmodels)
CrossTable(x = iris_test_category, y = pr, prop.chisq=FALSE)
plot(iris_target_category)
qplot (iris_target_category, data=iris, color=Species)
qplot (iris_test_category, data=iris, color=Species)
rlang::last_error()
qplot (iris_test_category, data=iris, color=Species)
qplot (iris_train,iris_test, data=iris, color=Species)
qplot (iris_train,iris_test, data=iris, color=Species)
qplot (iris_train,iris_test,cl=iris_target_category , color=Species)
qplot (pr, data=iris, color=Species)
plot(iris_target_category)
plot(iris_target_category)
qplot (Petal.Length, Petal.Width, data=iris, color=Species)
plot(iris_target_category)
qplot (Petal.Length, Petal.Width, data=iris, color=Species)
qplot (Sepal.Length, Sepal.Width, data=iris, color=Species)
plot(iris_target_category)
plot(iris_test_category)
plot(iris_test)
plot(iris_target)
plot(iris_train)
plot(tab)
plot(tab, colors=species)
plot(tab, colors=Species)
plot(pr)
plot(tab)
plot(iris_train)
plot(iris_test)
plot(iris_target_category)
#plot
plot(iris_test)
plot(iris_train)
plot(pr)
plot(tab)
plot(iris_target_category)
plot(iris_test_category)
# Libraries
library(caret)
library(pROC)
library(mlbench)
qplot (Petal.Length, Petal.Width, data=iris, color=Species)
#load data
df <- data(iris)
# see the studcture
head(iris)
#Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(iris), 0.9 * nrow(iris))
#the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
#Run nomalization on first 4 coulumns of dataset because they are the predictors
iris_norm <- as.data.frame(lapply(iris[,c(1,2,3,4)], nor))
summary(iris_norm)
#extract training set
iris_train <- iris_norm[ran,]
#extract testing set
iris_test <- iris_norm[-ran,]
#extract 5th column of train dataset because it will be used as 'cl' argument in knn function.
iris_target_category <- iris[ran,5]
#extract 5th column if test dataset to measure the accuracy
iris_test_category <- iris[-ran,5]
#load the package class
library(class)
#run knn function
pr <- knn(iris_train,iris_test,cl=iris_target_category,k=5)
print(pr,digits = 3)
#create confusion matrix
tab <- table(pr,iris_test_category)
print(tab,digits = 3)
#this function divides the correct predictions by total number of predictions that tell us how accurate teh model is.
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
#Cross Table
library(gmodels)
CrossTable(x = iris_test_category, y = pr, prop.chisq=FALSE)
#plot
plot(iris_test)
plot(iris_train)
plot(pr)
plot(tab)
plot(iris_target_category)
plot(iris_test_category)
#plot
plot(iris_test)
plot(iris_train)
plot(pr)
plot(tab)
plot(iris_test_category)
plot(iris_target_category)
> x <- 1 > print (x)
